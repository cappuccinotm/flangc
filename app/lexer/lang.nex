/'/                            { token.Kind = SQuote                           /* 0 */}
/quote/                        { token.Kind = Quote                            /* 1 */}
/\(/                           { token.Kind = LBrace                           /* 2 */}
/\)/                           { token.Kind = RBrace                           /* 3 */}
/((\+|-)?([0-9]+)(\.[0-9]+)?)|((\+|-)?\.?[0-9]+)/    {
  token.Kind = Number
  token.Value, *err = strconv.ParseFloat(yylex.Text(), 64)                    /* 4 */
}
/null/                         { token.Kind = Null                             /* 5 */}
/[a-z][a-z0-9]*/               {
  token.Kind = Identifier
  token.Value = yylex.Text()                                                  /* 6 */
}
/[ \t\n]+/                     { /* eat up whitespace */                       /* 7 */}
/\/\/[^\n\r]+?(?:\*\)|[\n\r])/ { /* eat up one-line comments */                /* 8 */}
/./                            { *err = ErrUnrecognizedCharacter(yylex.Text()) /* 9 */}
//
package lexer
func NewAdapter(r io.Reader) *Adapter {
  lex := NewLexer(r)
  svc := &Adapter {
    lexer: lex,
    nextTokenFunc: func(token *Token, err *error) {
      NN_FUN(lex)
    },
  }
  return svc
}